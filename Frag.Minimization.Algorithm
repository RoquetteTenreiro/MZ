
library(knitr)
library(sf)
library(dplyr)  
library(plyr)
library(reshape2)
library(agricolae)
library(quantreg)
library(plotly)
library(sp)
library(spDataLarge)
library(spData)
library(tmap)
library(raster)
library(gridExtra)
library(quantreg)
library(ggplot2)
library(RColorBrewer)
library(tidyverse)
library(gridExtra)
library(wesanderson)
library(ggpmisc)
library(markdown)
library(tinytex)
library(lmtest)

## Initial details Working directory

In this section we set initial details to specify the working directory; 
in this particular case the analysis was linked to the internal folder "Experimental_Catchment_Cordoba_19_20" where input and output data is saved. To run this code please specify the working directory where your input files are saved. 

```{r setup, include=FALSE}
rm(list=ls())
getwd()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/Tomas R. Tenreiro/Desktop/Experimental_Catchment_Cordoba_19_20")

```

## Input material

This section uploads all input material. In this particular case, we will work with satellite data (Landsat-8 and Sentinel-2), atmospherically corrected (and cloud cover < 4%), that was downloaded from EO-browser "https://apps.sentinel-hub.com/". The script considers imagery from five growing seasons (i.e. 2015, 2016, 2017, 2018 and 2019). In order to explore spatial correlation between plant vigor and soil properties under rainfed conditions, we focused on late phenological stages before crop senescence. 2015 and 2017 imagery corresponds to a sunflower crop, 2016 and 2018 to a winter wheat crop and 2019 imagery corresponds to a canola crop. 

Year | Crop             | Date 1     | Date 2     | Satellite

2015 | Sunflower        | 20/05/2015 | ---------  | Landsat-8
2016 | Wheat (durum)    | 03/03/2016 | ---------  | Landsat-8
2017 | Sunflower        | 22/05/2017 | 11/06/2017 | Sentinel-2
2018 | Wheat (durum)    | 28/03/2018 | 14/04/2018 | Sentinel-2
2019 | Canola           | 14/04/2019 | 12/05/2019 | Sentinel-2
 

```{r}

# Date 2015 -1
Red.2015.1 <- raster("SAT Imagery/Red.20.05.2015.tiff")
NIR.2015.1 <- raster("SAT Imagery/NIR.20.05.2015.tiff")

# Date 2016 -1
Red.2016.1 <- raster("SAT Imagery/Red.03.03.2016.tiff")
NIR.2016.1 <- raster("SAT Imagery/NIR.03.03.2016.tiff")

# Date 2017 -1
Red.2017.1 <- raster("SAT Imagery/Red.22.05.2017.tiff")
NIR.2017.1 <- raster("SAT Imagery/NIR.22.05.2017.tiff")

# Date 2017 -2
Red.2017.2 <- raster("SAT Imagery/Red.11.06.2017.tiff")
NIR.2017.2 <- raster("SAT Imagery/NIR.11.06.2017.tiff")

# Date 2018 -1
Red.2018.1 <- raster("SAT Imagery/Red.28.03.2018.tiff")
NIR.2018.1 <- raster("SAT Imagery/NIR.28.03.2018.tiff")

# Date 2018 -2
Red.2018.2 <- raster("SAT Imagery/Red.14.04.2018.tiff")
NIR.2018.2 <- raster("SAT Imagery/NIR.14.04.2018.tiff")

# Date 2019 -1
Red.2019.1 <- raster("SAT Imagery/Red.14.04.2019.tiff")
NIR.2019.1 <- raster("SAT Imagery/NIR.14.04.2019.tiff")

# Date 2019 -2
Red.2019.2 <- raster("SAT Imagery/Red.12.05.2019.tiff")
NIR.2019.2 <- raster("SAT Imagery/NIR.12.05.2019.tiff")

```

## Estimate NDVI 

This section estimates NDVI considering that Landsat-8 satellite B4 corresponds to Red wave length and B5 to NIR wave length; Sentinel-2 satellite B4 corresponds to Red wave length and B8 to NIR wave length. Data is in raster format with a spatial resolution of 30x30m (Landsat-8) or 10x10m (Sentinel-2).

```{r}

# NDVI 2015
NDVI_2015.1 <- (NIR.2015.1 - Red.2015.1) / (NIR.2015.1 + Red.2015.1)

# NDVI 2016
NDVI_2016.1 <- (NIR.2016.1 - Red.2016.1) / (NIR.2016.1 + Red.2016.1)

# NDVI 2017
NDVI_2017.1 <- (NIR.2017.1 - Red.2017.1) / (NIR.2017.1 + Red.2017.1)
NDVI_2017.2 <- (NIR.2017.2 - Red.2017.2) / (NIR.2017.2 + Red.2017.2)

# NDVI 2018
NDVI_2018.1 <- (NIR.2018.1 - Red.2018.1) / (NIR.2018.1 + Red.2018.1)
NDVI_2018.2 <- (NIR.2018.2 - Red.2018.2) / (NIR.2018.2 + Red.2018.2)

# NDVI 2019
NDVI_2019.1 <- (NIR.2019.1 - Red.2019.1) / (NIR.2019.1 + Red.2019.1)
NDVI_2019.2 <- (NIR.2019.2 - Red.2019.2) / (NIR.2019.2 + Red.2019.2)

```

## Create maps of NDVI with 'tm_shape' function applied to raster data (tm_raster)

Important to make sure we have uploaded the library 'tmap'

```{r}

# Map NDVI 2015
NDVI_2015.1_map <- tm_shape(NDVI_2015.1) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)

# Map NDVI 2016
NDVI_2016.1_map <- tm_shape(NDVI_2016.1) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)

# Map NDVI 2017
NDVI_2017.1_map <- tm_shape(NDVI_2017.1) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)
NDVI_2017.2_map <- tm_shape(NDVI_2017.2) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)

# Map NDVI 2016
NDVI_2018.1_map <- tm_shape(NDVI_2018.1) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)
NDVI_2018.2_map <- tm_shape(NDVI_2018.2) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)

# Map NDVI 2017
NDVI_2019.1_map <- tm_shape(NDVI_2019.1) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)
NDVI_2019.2_map <- tm_shape(NDVI_2019.2) + tm_raster(palette="YlGn",n=5) + tm_legend(outside = TRUE, text.size = 1.2)


```

## Visualize NDVI raster maps 

First for 2015 (ncol means the number of columns up to a maximum limit of 4 features)

```{r}
tmap_arrange(NDVI_2015.1_map, 
            ncol=1)
```

For 2016

```{r}
tmap_arrange(NDVI_2016.1_map, 
             ncol=2)
```

For 2017

```{r}
tmap_arrange(NDVI_2017.1_map, 
             NDVI_2017.2_map, 
             ncol=2)
```

For 2018

```{r}
tmap_arrange(NDVI_2018.1_map, 
             NDVI_2018.2_map, 
             ncol=2)
```

For 2019

```{r}
tmap_arrange(NDVI_2019.1_map, 
             NDVI_2019.2_map, 
             ncol=2)
```

## Upload the field vector for clip operations

The field vector selected should be the shapefile polygon of the field. In this particular case, the shapefile was obtained with QGIS considering a topographic characterization of the selected catchment. The catchment was spatially defined according to a map of flow directions (raster) obtained with the SAGA - Wang & Liu algorithm. The algorithm defines water flow and hillshades orientation in a particular area of interest from a DEM. We used a DEM with 5m spatial resolution obtained with LiDAR from CNIG (http://centrodedescargas.cnig.es/CentroDescargas/index.jsp). From that information, a catchment was isolated with an area of approximately 9.5 ha.

```{r}

# Upload field vector
field_vector <- st_read("sentinel/R_analysis/Field_vector.shp")
plot (field_vector$geometry)

```

In this step it is also important to check whether the coordinate system is the same as of satellite imagery; in this particular case we will work with the system WGS84 EPSG 4326. 

```{r}

# Check coordinate system
crs(field_vector)
crs(NDVI_2016.1) # as an example to check coordinate system of rasters

```

## Cropping and Masking tools

In the following section the script crops and masks the NDVI maps by the field vector shapefile.
For more info about these functions please check the outcome and have a look at the following link "https://rpubs.com/ricardo_ochoa/416711"

```{r}

# Crop NDVI data 2015
cropped_feature_2015.1 = crop(NDVI_2015.1, field_vector)
plot (cropped_feature_2015.1)

# Mask NDVI data 2015
masked_feature_2015.1 = mask(NDVI_2015.1, field_vector)
plot(masked_feature_2015.1)

# Crop NDVI data 2016
cropped_feature_2016.1 = crop(NDVI_2016.1, field_vector)
plot (cropped_feature_2016.1)

# Mask NDVI data 2016
masked_feature_2016.1 = mask(NDVI_2016.1, field_vector)
plot(masked_feature_2016.1)

# Crop NDVI data 2017
cropped_feature_2017.1 = crop(NDVI_2017.1, field_vector)
plot (cropped_feature_2017.1)
cropped_feature_2017.2 = crop(NDVI_2017.2, field_vector)
plot (cropped_feature_2017.2)

# Mask NDVI data 2017
masked_feature_2017.1 = mask(NDVI_2017.1, field_vector)
plot(masked_feature_2017.1)
masked_feature_2017.2 = mask(NDVI_2017.2, field_vector)
plot(masked_feature_2017.2)

# Crop NDVI data 2018
cropped_feature_2018.1 = crop(NDVI_2018.1, field_vector)
plot (cropped_feature_2018.1)
cropped_feature_2018.2 = crop(NDVI_2018.2, field_vector)
plot (cropped_feature_2018.2)

# Mask NDVI data 2018
masked_feature_2018.1 = mask(NDVI_2018.1, field_vector)
plot(masked_feature_2018.1)
masked_feature_2018.2 = mask(NDVI_2018.2, field_vector)
plot(masked_feature_2018.2)

# Crop NDVI data 2019
cropped_feature_2019.1 = crop(NDVI_2019.1, field_vector)
plot (cropped_feature_2019.1)
cropped_feature_2019.2 = crop(NDVI_2019.2, field_vector)
plot (cropped_feature_2019.2)

# Mask NDVI data 2019
masked_feature_2019.1 = mask(NDVI_2019.1, field_vector)
plot(masked_feature_2019.1)
masked_feature_2019.2 = mask(NDVI_2019.2, field_vector)
plot(masked_feature_2019.2)

```

## Visualization mode: Interactive (view) vs. Static (plot) viewing 

Here we switch to an interactive viewing mode of outcomes. 
If you want to get back to the "static" mode please switch 'view' by 'plot' in the function term 'tmap_mode()'

```{r}

tmap_mode("view") 
# or tmap_mode("plot") instead

```

## Interactive mapping of masked NDVI rasters

```{r}

# For 2015
masked_2015.1 <- tm_shape(masked_feature_2015.1) + tm_raster(palette="YlGn",n=10, title="NDVI_05.06.2015") + tm_legend(outside = TRUE, text.size = 1.2)

# For 2016
masked_2016.1 <- tm_shape(masked_feature_2016.1) + tm_raster(palette="YlGn",n=10, title="NDVI_07.06.2016") + tm_legend(outside = TRUE, text.size = 1.2)

# For 2017
masked_2017.1 <- tm_shape(masked_feature_2017.1) + tm_raster(palette="YlGn",n=10, title="NDVI_10.06.2017") + tm_legend(outside = TRUE, text.size = 1.2)
masked_2017.2 <- tm_shape(masked_feature_2017.2) + tm_raster(palette="YlGn",n=10, title="NDVI_26.06.2017") + tm_legend(outside = TRUE, text.size = 1.2)

# For 2018
masked_2018.1 <- tm_shape(masked_feature_2018.1) + tm_raster(palette="YlGn",n=10, title="NDVI_22.05.2018") + tm_legend(outside = TRUE, text.size = 1.2)
masked_2018.2 <- tm_shape(masked_feature_2018.2) + tm_raster(palette="YlGn",n=10, title="NDVI_03.06.2018") + tm_legend(outside = TRUE, text.size = 1.2)

# For 2019
masked_2019.1 <- tm_shape(masked_feature_2019.1) + tm_raster(palette="YlGn",n=10, title="NDVI_14.04.2019") + tm_legend(outside = TRUE, text.size = 1.2)
masked_2019.2 <- tm_shape(masked_feature_2019.2) + tm_raster(palette="YlGn",n=10, title="NDVI_27.04.2019") + tm_legend(outside = TRUE, text.size = 1.2)

```

## Print NDVI masked map for 2015 and 2016

```{r}
tmap_arrange(masked_2015.1,
             masked_2016.1,
             ncol=2)
```


# Print NDVI masked map for 2017

```{r}
tmap_arrange(masked_2017.1,
             masked_2017.2,
             ncol=2)
```

# Print NDVI masked map for 2018

```{r}
tmap_arrange(masked_2018.1,
             masked_2018.2,
             ncol=2)
```

# Print NDVI masked map for 2019

```{r}
tmap_arrange(masked_2019.1,
             masked_2019.2,
             ncol=2)
```

# Display facets for 2015

1) We convert 2015 raster data into vectorial point-based data while keeping the same (Landsat-8) spatial resolution (30x30m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2015).

```{r}

# From raster to point
NDVI_vector_2015.1 <- rasterToPoints(masked_feature_2015.1, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2015.1)[names(NDVI_vector_2015.1) == "layer"] <- "NDVI_2015.1"

# Create maps for 2016
NDVI_points_2015.1 <- tm_shape(NDVI_vector_2015.1) + tm_dots(col="NDVI_2015.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)


```

# Display facets for 2016

1) We convert 2016 raster data into vectorial point-based data while keeping the same (Landsat-8) spatial resolution (30x30m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2016).

```{r}

# From raster to point
NDVI_vector_2016.1 <- rasterToPoints(masked_feature_2016.1, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2016.1)[names(NDVI_vector_2016.1) == "layer"] <- "NDVI_2016.1"

# Create maps for 2016
NDVI_points_2016.1 <- tm_shape(NDVI_vector_2016.1) + tm_dots(col="NDVI_2016.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)

# Display facets for both 2015 and 2016
tmap_arrange(NDVI_points_2015.1,
             NDVI_points_2016.1,
             ncol=2)

```

# Display facets for 2016

1) We convert 2016 raster data into vectorial point-based data while keeping the same (Landsat-8) spatial resolution (30x30m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2016).

```{r}

# From raster to point
NDVI_vector_2016.1 <- rasterToPoints(masked_feature_2016.1, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2016.1)[names(NDVI_vector_2016.1) == "layer"] <- "NDVI_2016.1"

# Create maps for 2016
NDVI_points_2016.1 <- tm_shape(NDVI_vector_2016.1) + tm_dots(col="NDVI_2016.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)

# Display facets for both 2015 and 2016
tmap_arrange(NDVI_points_2015.1,
             NDVI_points_2016.1,
             ncol=2)

```

# Display facets for 2017

1) We convert 2017 raster data into vectorial point-based data while keeping the same (Landsat-8) spatial resolution (30x30m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2017).

```{r}

# From raster to point
NDVI_vector_2017.1 <- rasterToPoints(masked_feature_2017.1, spatial = TRUE) %>% st_as_sf()
NDVI_vector_2017.2 <- rasterToPoints(masked_feature_2017.2, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2017.1)[names(NDVI_vector_2017.1) == "layer"] <- "NDVI_2017.1"
names(NDVI_vector_2017.2)[names(NDVI_vector_2017.2) == "layer"] <- "NDVI_2017.2"

# Create maps for 2016
NDVI_points_2017.1 <- tm_shape(NDVI_vector_2017.1) + tm_dots(col="NDVI_2017.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)
NDVI_points_2017.2 <- tm_shape(NDVI_vector_2017.2) + tm_dots(col="NDVI_2017.2", palette="YlGn", n=10) + tm_style("cobalt") + 
  tm_legend(outside = TRUE, text.size = 1.2)

# Display facets
tmap_arrange(NDVI_points_2017.1,
             NDVI_points_2017.2,
             ncol=2)

```

# Display facets for 2018

1) We convert 2018 raster data into vectorial point-based data while keeping the same (Sentinel-2) spatial resolution (10x10m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2018).

```{r}

# From raster to point
NDVI_vector_2018.1 <- rasterToPoints(masked_feature_2018.1, spatial = TRUE) %>% st_as_sf()
NDVI_vector_2018.2 <- rasterToPoints(masked_feature_2018.2, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2018.1)[names(NDVI_vector_2018.1) == "layer"] <- "NDVI_2018.1"
names(NDVI_vector_2018.2)[names(NDVI_vector_2018.2) == "layer"] <- "NDVI_2018.2"

# Create maps for 2016
NDVI_points_2018.1 <- tm_shape(NDVI_vector_2018.1) + tm_dots(col="NDVI_2018.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)
NDVI_points_2018.2 <- tm_shape(NDVI_vector_2018.2) + tm_dots(col="NDVI_2018.2", palette="YlGn", n=10) + tm_style("cobalt") + 
  tm_legend(outside = TRUE, text.size = 1.2)

# Display facets
tmap_arrange(NDVI_points_2018.1,
             NDVI_points_2018.2,
             ncol=2)

```

# Display facets for 2019

1) We convert 2019 raster data into vectorial point-based data while keeping the same (Sentinel-2) spatial resolution (10x10m). 

2) Use of 'tmap_arrange' to display facets for NDVI vectorial mapping (2019).

```{r}

# From raster to point
NDVI_vector_2019.1 <- rasterToPoints(masked_feature_2019.1, spatial = TRUE) %>% st_as_sf()
NDVI_vector_2019.2 <- rasterToPoints(masked_feature_2019.2, spatial = TRUE) %>% st_as_sf()

# Correct feature name
names(NDVI_vector_2019.1)[names(NDVI_vector_2019.1) == "layer"] <- "NDVI_2019.1"
names(NDVI_vector_2019.2)[names(NDVI_vector_2019.2) == "layer"] <- "NDVI_2019.2"

# Create maps for 2016
NDVI_points_2019.1 <- tm_shape(NDVI_vector_2019.1) + tm_dots(col="NDVI_2019.1", palette="YlGn", n=10) + tm_style("cobalt") + 
tm_legend(outside = TRUE, text.size = 1.2)
NDVI_points_2019.2 <- tm_shape(NDVI_vector_2019.2) + tm_dots(col="NDVI_2019.2", palette="YlGn", n=10) + tm_style("cobalt") + 
  tm_legend(outside = TRUE, text.size = 1.2)

# Display facets
tmap_arrange(NDVI_points_2019.1,
             NDVI_points_2019.2,
             ncol=2)

```


## Display sampling and ECa measuring photos

Some photos of the measures taken with a Dualem sensor (i.e. electromagnetic induction sensor), spatial resolution of 1x15m. Soil ECa was measured at 35 and 85 cm depth before sowing and a few days after a rainfall event of aprox. 10 mm. Soil samples were also collected to estimate pH and clay content. 

For more info in regard to ECa sensing/mapping please read:

- Johnson, C. K., Doran, J. W., Duke, H. R., Wienhold, B. J., Eskridge, K. M., & Shanahan, J. F. (2001). Field-scale electrical conductivity mapping for delineating soil condition. Soil Science Society of America Journal, 65(6), 1829-1837.

- McCutcheon, M. C., Farahani, H. J., Stednick, J. D., Buchleiter, G. W., & Green, T. R. (2006). Effect of soil water on apparent soil electrical conductivity and texture relationships in a dryland field. Biosystems Engineering, 94(1), 19-32.

```{r}

# Upload libraries 'imager' and 'png'
library(knitr)    # For knitting document and include_graphics function
library(ggplot2)  # For plotting
library(png)      # For grabbing the dimensions of png files

#Define file ath
img1_path <- "sentinel/R_analysis/Pictures_Sampling/1.png"
img2_path <- "sentinel/R_analysis/Pictures_Sampling/2.png"
img3_path <- "sentinel/R_analysis/Pictures_Sampling/3.png"
img4_path <- "sentinel/R_analysis/Pictures_Sampling/4.png"
img5_path <- "sentinel/R_analysis/Pictures_Sampling/3.png"
img6_path <- "sentinel/R_analysis/Pictures_Sampling/4.png"

# Display pictures
include_graphics(img1_path) 
include_graphics(img2_path) 
include_graphics(img3_path) 
include_graphics(img4_path) 
include_graphics(img5_path) 
include_graphics(img6_path) 

```

## Upload soil physical and chemical data 

Data collected at 10th October 2019 
Field location: Guadálcazar, Córdoba, Spain

Four different types of properties:
1) Soil texture (%Clay, %Sand);
2) Soil ECa (35 and 85 cm depth);
3) Slope orientation;
4) Elevation (m);

```{r}

# Upload raster data
GF_Elevation     <- raster("GF_Elevation.tif")
GF_Orientation   <- raster("GF_Orientation.tif")
GF_ECa1          <- raster("GF_CEa1.tif")
GF_ECa2          <- raster("GF_CEa2.tif")

# Convert to point vectorial data
GF_Elevation_dots <- rasterToPoints(GF_Elevation, spatial = TRUE) %>% st_as_sf()
names(GF_Elevation_dots)[names(GF_Elevation_dots) == "GF_Elevation"] <- "Elevation"
GF_Orientation_dots <- rasterToPoints(GF_Orientation, spatial = TRUE) %>% st_as_sf()
names(GF_Orientation_dots)[names(GF_Orientation_dots) == "GF_Orientation"] <- "Orientation"
GF_ECa1_dots <- rasterToPoints(GF_ECa1, spatial = TRUE) %>% st_as_sf()
names(GF_ECa1_dots)[names(GF_ECa1_dots) == "GF_CEa1"] <- "ECa1"
GF_ECa2_dots <- rasterToPoints(GF_ECa2, spatial = TRUE) %>% st_as_sf()
names(GF_ECa2_dots)[names(GF_ECa2_dots) == "GF_CEa2"] <- "ECa2"

```

## Join field data and NDVI data on a single shapefile

Here we run a spatial join in order to build a single shapefile containing point based data (10x10m) with plant vigor (NDVI), soil physical properties (elevation, orientation, ECa, texture) and chemical data (pH).
 
```{r}

# Start spatial join (NDVI + Elevation + Orientation + ECa)
rm(MZ_joined)
MZ_joined = st_join(NDVI_vector_2019.1, NDVI_vector_2019.2["NDVI_2019.2"], join = st_nearest_feature)

MZ_joined = st_join(MZ_joined, NDVI_vector_2018.1["NDVI_2018.1"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, NDVI_vector_2018.2["NDVI_2018.2"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, NDVI_vector_2017.1["NDVI_2017.1"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, NDVI_vector_2017.2["NDVI_2017.2"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, NDVI_vector_2016.1["NDVI_2016.1"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, NDVI_vector_2015.1["NDVI_2015.1"], join = st_nearest_feature)

MZ_joined = st_join(MZ_joined, GF_Elevation_dots["Elevation"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, GF_Orientation_dots["Orientation"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, GF_ECa1_dots["ECa1"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, GF_ECa2_dots["ECa2"], join = st_nearest_feature)

# Convert Eca from mS/m to dS/m and estimate ECa mean
MZ_joined$ECa1     <- MZ_joined$ECa1/100
MZ_joined$ECa2     <- MZ_joined$ECa2/100
MZ_joined$EC_mean  <- ((MZ_joined$ECa1+MZ_joined$ECa2)/2)

# A simple classification of soil texture proposed by Greenfields: http://www.greenfield.agrodrone.es/ 
MZ_joined$Texture  <- "Clay_loamy"
MZ_joined$Texture[MZ_joined$ECa2 > 0.60]  <- "Clay"
MZ_joined$Texture[MZ_joined$ECa1 < 0.10]  <- "Clay_loamy"
tm_shape(MZ_joined) + tm_dots(col = "Texture", palette = "RdYlGn", n=2) + tm_style("cobalt")

```

# Soil sampling for pH and %clay mapping

A total of 10 soil samples were collected at 40cm according to a clustering of ECa. Data is spatially interpolated following a 'nearest-feature' algorithm in order to produce point based vectorial maps with the same spatial resolution of MZ_joined.  

```{r}

# Upload sampling dots
Sampling_vector <- st_read("Sampling_dots.shp")
Sampling_map    <- tm_shape(Sampling_vector) + tm_dots(col = "green", palette = "RdYlGn", n=6) + tm_style("cobalt")
Sampling_map  

# Rename: translating from Spanish to English
names(Sampling_vector)[names(Sampling_vector) == "ARCILLA"] <- "Clay"
names(Sampling_vector)[names(Sampling_vector) == "PH"] <- "pH"
names(Sampling_vector)[names(Sampling_vector) == "ARENA"] <- "Sand"

```

A few sampling photos

```{r}

#Define file path
img7_path <- "sentinel/R_analysis/Pictures_Sampling/7.png"
img8_path <- "sentinel/R_analysis/Pictures_Sampling/8.png"

# Display pictures
include_graphics(img7_path) 
include_graphics(img8_path) 

```

```{r}

# Spatial join
MZ_joined = st_join(MZ_joined, Sampling_vector["Clay"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, Sampling_vector["pH"], join = st_nearest_feature)
MZ_joined = st_join(MZ_joined, Sampling_vector["Sand"], join = st_nearest_feature)

# Map sampling points
Clay_map <- tm_shape(MZ_joined) + tm_dots(col = "Clay", palette = "YlOrBr", n=8, size = 0.3) #+ tm_style("cobalt") 
Sand_map <- tm_shape(MZ_joined) + tm_dots(col = "Sand", palette = "Oranges", n=8, size = 0.3) #+ tm_style("cobalt") 
pH_map   <- tm_shape(MZ_joined) + tm_dots(col = "pH", palette = "Blues", n=5, size = 0.3) #+ tm_style("cobalt")

# Display
tmap_mode("plot") 
tmap_arrange(Clay_map,
             Sand_map,
             pH_map,
             ncol=3)

```

```{r}

# Estimate CV
cv_Clay      = cv(MZ_joined$Clay)
cv_Sand      = cv(MZ_joined$Sand)
cv_pH        = cv(MZ_joined$pH)

cv_ECa1      = cv(MZ_joined$ECa1)
cv_ECa2      = cv(MZ_joined$ECa2)
cv_O         = cv(MZ_joined$Orientation)
cv_E         = cv(MZ_joined$Elevation)

cv_NDVI_2019.1 = cv(MZ_joined$NDVI_2019.1)
cv_NDVI_2019.2 = cv(MZ_joined$NDVI_2019.2)
cv_NDVI_2018.1 = cv(MZ_joined$NDVI_2018.1)
cv_NDVI_2018.2 = cv(MZ_joined$NDVI_2018.2)
cv_NDVI_2017.1 = cv(MZ_joined$NDVI_2017.1)
cv_NDVI_2017.2 = cv(MZ_joined$NDVI_2017.2)
cv_NDVI_2016.1 = cv(MZ_joined$NDVI_2016.1)
cv_NDVI_2015.1 = cv(MZ_joined$NDVI_2015.1)


# Print results
# cv_Clay = 6.65 %
# cv_Sand = 25.97 %
# cv_pH = 3.32 %
# cv_ECa1 = 39.38 %
# cv_ECa2 = 26.77 %
# cv_O = 61.83 %
# cv_E = 4.86

# cv_NDVI_2019.1 = 13.16 %
# cv_NDVI_2019.2 = 11.97 %

# cv_NDVI_2018.1 = 16.53 %
# cv_NDVI_2018.2 = 18.01 %

# cv_NDVI_2017.1 = 10.08 %
# cv_NDVI_2017.2 = 11.13 %

# cv_NDVI_2016.1 = 10.21 %
# cv_NDVI_2016.2 = 7.47 %

# cv_NDVI_2015.1 = 13.99 %
# cv_NDVI_2015.2 = 10.68 %

```

## Filtering data with PCA 

```{r}

install.packages("devtools")
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
install.packages("factoextra")
library(factoextra)
install.packages("ggfortify")
library(ggfortify)
library(cluster)

```


```{r}

MZ_joined$NDVI_2019 <- ((MZ_joined$NDVI_2019.1 + MZ_joined$NDVI_2019.2) / 2)
MZ_joined$NDVI_2018 <- ((MZ_joined$NDVI_2018.1 + MZ_joined$NDVI_2018.2) / 2)
MZ_joined$NDVI_2017 <- ((MZ_joined$NDVI_2017.1 + MZ_joined$NDVI_2017.2) / 2)
MZ_joined$NDVI_2016 <- ((MZ_joined$NDVI_2016.1))
MZ_joined$NDVI_2015 <- ((MZ_joined$NDVI_2015.1))

MZ_joined$ID <- seq.int(nrow(MZ_joined))

rm(dataframe)
dataframe = fortify(MZ_joined)
dataframe$geometry <- NULL

dataframe <- dataframe[,c(9:12,15:17,18:23)]

data.pca <- prcomp(dataframe[,c(1:12)], scale = TRUE)

summary(data.pca)
autoplot(data.pca, colour = 'white', loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3.5)

data.pca$rotation

```

# Weather data to explore year effect

```{r}

rm(Year_effect)
Year_effect <- data.frame(matrix(ncol = 3, nrow = 5))
colnames(Year_effect) <- c("Year", "Water_i","PC_score")

Year_effect$Year <- matrix(c("2019","2018","2017","2016","2015"),ncol=1,byrow = TRUE)

Year_effect$Water_i <- matrix(as.numeric(c("0.46", "0.06","0.29","0.27","0.47")),ncol=1,byrow = TRUE)

Year_effect$PC_score <- matrix(as.numeric(c("0.509","0.558","0.701","0.447","0.521")),ncol=1,byrow = TRUE)

ggplot(Year_effect, aes(x = Water_i, y = PC_score)) + geom_point() + theme_classic() +
  geom_text(aes(label=Year)) + scale_x_continuous() 
	#geom_line(color='darkgreen', size=2, alpha=0.4, linetype=2) + geom_point(shape=21, color="black", fill="#69b3a2", size=6) +
	
```


# Build my dataframe

```{r}

library(cluster)

data <- dataframe[c(1,4,6,8,10,12,13)]
#data <- dataframe[c(1,3,5:6,8:10,12,13)]
data.scale <- scale(data[,c(1:7)])
#data.scale <- scale(data[,c(1:8)])
#' Compute Gower distance
rm(gower_dist)
gower_dist <- daisy(data.scale, metric = "gower")
rm(gower_mat)
gower_mat <- as.matrix(gower_dist)
#' Print most similar points
data.scale[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]), arr.ind = TRUE)[1, ], ]

#' Print most dissimilar points
data.scale[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]

sil_width <- c(NA)
for(i in 2:5){  
  pam_fit <- pam(gower_dist, diss = TRUE, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width  
}
plot(1:5, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:5, sil_width)

```

```{r}
fviz_nbclust(data.scale, FUN = hcut, method = "wss")

# Elbow method
fviz_nbclust(data.scale, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")

# Silhouette method
fviz_nbclust(data.scale, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

# Gap statistic
# nboot = 50 to keep the function speedy. 
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.

# Gap statistic
fviz_nbclust(data.scale, kmeans, method = "gap_stat")+
  labs(subtitle = "Gap Stat method")

```


# The parameters to cluster MZ 

Applying k-means to the dataset

``` {r}

library(dplyr)
library(corrplot)
library(gridExtra)
library(GGally)
library(cluster) # clustering algorithms 
library(factoextra) 
```

## K-MEANS algorithm to Map Management Zones 

```{r}

# Define FIRST the number of clusters
nk = 4

rm(data_1)
data_1 <- data.scale
df.1 <- data
data.scale_1 <- data_1

rm(cluster)
set.seed(125)
cluster <- kmeans(data.scale_1, nk)
df.1$cluster <- cluster$cluster

# Plot the cluster
fviz_cluster(cluster, data = df.1)

# Add clusters to spatial data
rm(mergedata)
df.1 <- df.1[c(7,8)]
#df.1 <- df.1[c(9,10)]
mergedata <- merge(x = MZ_joined, y = df.1, by = "ID")

# Recall data
names(mergedata)[names(mergedata) == "cluster"] <- "ZONE"

# Prepare map
mergedata$ZONE[mergedata$ZONE == "1"] <- "A"
mergedata$ZONE[mergedata$ZONE == "2"] <- "B"
mergedata$ZONE[mergedata$ZONE == "3"] <- "C"
mergedata$ZONE[mergedata$ZONE == "4"] <- "D"
mergedata$ZONE[mergedata$ZONE == "5"] <- "E"
mergedata$ZONE[mergedata$ZONE == "6"] <- "F"
mergedata$ZONE[mergedata$ZONE == "7"] <- "G"
mergedata$ZONE[mergedata$ZONE == "8"] <- "H"

mycols <- c("#3CB371", "#7B68EE", "#FFA07A", "#FFD700")
map_ZONE             <- tm_shape(mergedata) + tm_dots(size = 0.8, col = "ZONE", palette = mycols, n=5) + tm_style("bw") 

map_ZONE
# Simulated Yield maps from NDVI

# For canola 2019
mergedata$Yield_2019 <- 0
mergedata$NDVI_2019[mergedata$NDVI_2019<0] <- 0
mergedata$NDVI_2019[mergedata$NDVI_2019>1] <- 1
mergedata$Yield_2019 <- (-2.24*(mergedata$NDVI_2019^2))+(4.875*mergedata$NDVI_2017)  
mergedata$Yield_2019[mergedata$Yield_2019<0] <- 0

# For wheat 2018
mergedata$Yield_2018 <- 0
mergedata$NDVI_2018[mergedata$NDVI_2018<0] <- 0
mergedata$NDVI_2018[mergedata$NDVI_2018>1] <- 1
mergedata$Yield_2018 <- (7.9998*mergedata$NDVI_2018)
mergedata$Yield_2018[mergedata$Yield_2018<0] <- 0

# For sunflower 2017
mergedata$Yield_2017 <- 0
mergedata$NDVI_2017[mergedata$NDVI_2017<0] <- 0
mergedata$NDVI_2017[mergedata$NDVI_2017>1] <- 1
mergedata$Yield_2017 <- (-2.411*(mergedata$NDVI_2017^2))+(4.608*mergedata$NDVI_2017)
mergedata$Yield_2017[mergedata$Yield_2017<0] <- 0

# For wheat 2016
mergedata$Yield_2016 <- 0
mergedata$NDVI_2016[mergedata$NDVI_2016<0] <- 0
mergedata$NDVI_2016[mergedata$NDVI_2016>1] <- 1
mergedata$Yield_2016 <- (7.9998*mergedata$NDVI_2016)
mergedata$Yield_2016[mergedata$Yield_2016<0] <- 0

# For sunflower 2015
mergedata$Yield_2015 <- 0
mergedata$NDVI_2015[mergedata$NDVI_2015<0] <- 0
mergedata$NDVI_2015[mergedata$NDVI_2015>1] <- 1
mergedata$Yield_2015 <- (-2.411*(mergedata$NDVI_2015^2))+(4.608*mergedata$NDVI_2015)
mergedata$Yield_2015[mergedata$Yield_2015<0] <- 0


# Map results

map_Yield.2015      <- tm_shape(mergedata) + tm_dots(col = "Yield_2015", palette = "RdYlGn", n=8) + tm_style("cobalt") 
map_Yield.2016      <- tm_shape(mergedata) + tm_dots(col = "Yield_2016", palette = "RdYlGn", n=8) + tm_style("cobalt") 
map_Yield.2017      <- tm_shape(mergedata) + tm_dots(col = "Yield_2017", palette = "RdYlGn", n=8) + tm_style("cobalt") 
map_Yield.2018      <- tm_shape(mergedata) + tm_dots(size = 0.8, col = "Yield_2018", palette = "RdYlGn", n=4) + tm_style("bw") 
map_Yield.2019      <- tm_shape(mergedata) + tm_dots(size = 0.8, col = "Yield_2019", palette = "RdYlGn", n=4) + tm_style("bw") 


# Display facets
tmap_arrange(map_ZONE,
             map_Yield.2015,
             map_Yield.2016,
             map_Yield.2017,
             ncol=4)

tmap_arrange(map_Yield.2018,
             map_Yield.2019,
             ncol=4)

tmap_arrange(map_Yield.2018,
             map_Yield.2019,
             map_ZONE,
             ncol=3)

```

## Algorithm to Minimize MZ fragmentation 

```{r}

# PLEASE INTRODUCE MINIMUM AREA SIZE OF EACH MANAGEMENT ZONE (sq meters)
m = 2500

library(spatstat)
library(maptools) 

rm(clusters)
clusters <- mergedata[,c(24,26)]
class(clusters)
sp_pts <- as(clusters, "Spatial")
class(sp_pts)

dat.pp <- as(dirichlet(as.ppp(sp_pts)), "SpatialPolygons")
dat.pp <- as(dat.pp,"SpatialPolygons")

# Sets the projection to British National Grid
proj4string(dat.pp) <- CRS("+init=EPSG:4326")
proj4string(sp_pts) <- CRS("+init=EPSG:4326")
# Assign to each polygon the data from House.Points
int.Z <- over(dat.pp,sp_pts)
# Create a SpatialPolygonsDataFrame
thiessen <- SpatialPolygonsDataFrame(dat.pp, int.Z)
# maps the thiessen polygons and House.Points
#tm_shape(Output.Areas) + tm_fill(alpha=.3, col = "grey") +
tm_shape(thiessen) + tm_fill(alpha=.3, col = "grey") + tm_borders(alpha=.5, col = "black") +
tm_shape(sp_pts) + tm_dots(col = "blue", scale = 0.5)

class(field_vector)

# maps cropped thiessen polygons and sp_pts
tm_shape(thiessen) + tm_fill(col="ZONE") + tm_borders(alpha=.5, col = "black") +
tm_shape(sp_pts) + tm_dots(col = "blue", scale = 0.5)

install.packages("spatialEco")
library(spatialEco)
df <- sp.na.omit(thiessen, margin = 1)

require("rgdal")
require("rgeos")
require("dplyr")
union <- unionSpatialPolygons(thiessen, thiessen@data[["ZONE"]])
polyd <- disaggregate(union)

tm_shape(polyd) + tm_fill(col="MAP_COLORS") + tm_borders(alpha=.5, col = "black") 

field_sp <- as(field_vector,"Spatial") 
class(field_sp)

library(GISTools)
union_clip <- gIntersection(field_sp, polyd, byid = TRUE, drop_lower_td = TRUE)
tm_shape(union_clip) + tm_polygons(col = "MAP_COLORS", n=8) 

rm(union_sf)
union_sf <- st_as_sf(union_clip)
union_sf$area <- st_area(union_sf)
union_sf$area <- as.numeric(union_sf$area)
union_sf.sub <- subset(union_sf, area > m)
tm_shape(union_sf.sub) + tm_polygons(col = "MAP_COLORS", palette = "RdYlGn", n=8) + tm_style("cobalt") 
union_sf.sub$ID <- seq.int(nrow(union_sf.sub))


rm(thiessen_sf)
thiessen_sf <- st_as_sf(thiessen)
m1 <- tm_shape(thiessen_sf) + tm_polygons(col = "ZONE", n=8) 

union_joined = st_join(union_sf.sub, thiessen_sf["ZONE"], join = st_contains)
m2 <- tm_shape(union_joined) + tm_polygons(col = "ZONE", n=8) 

tmap_arrange(m1,m2,ncol=2)

names(union_joined)[names(union_joined) == "ZONE"] <- "MZ"

mergedata = st_join(mergedata, union_joined["MZ"], join = st_nearest_feature)
map_MZ <- tm_shape(mergedata) + tm_dots(col = "MZ", size=0.6, palette = mycols) + tm_style("cobalt")

tmap_arrange(map_ZONE,map_MZ,ncol=2)

```
